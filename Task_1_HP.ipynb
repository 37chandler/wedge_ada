{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Build a Transaction Database in Google Big Query\n",
    "Loads files to GBQ, I was only able to get the small/inactive files to load with code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.io import gbq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_path = ' '\n",
    "service_file = ' ' # change this to your authentication information  \n",
    "gbq_proj_id = ' ' # change this to your project. \n",
    "gbq_dataset_id = ' ' # and change this to your data set ID\n",
    "\n",
    "# Creates private key \n",
    "private_key =service_path + service_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(service_path + service_file)\n",
    "\n",
    "# And create a client to talk to GBQ\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_table = \"transArchive_201304_201306_inactive_clean\"\n",
    "#my_table = \"transArchive_201301_201303_inactive_clean\"\n",
    "#my_table = \"transArchive_201210_201212_inactive_clean\"\n",
    "#my_table = \"transArchive_201207_201209_inactive_clean\"\n",
    "#my_table = \"transArchive_201204_201206_inactive_clean\"\n",
    "#my_table = \"transArchive_201201_201203_inactive_clean\"\n",
    "#my_table = \"transArchive_201307_201309_inactive_clean\"\n",
    "#my_table = \"transArchive_201310_201312_inactive_clean\"\n",
    "#my_table = \"transArchive_201401_201403_inactive_clean\"\n",
    "#my_table = \"transArchive_201404_201406_inactive_clean\"\n",
    "#my_table = \"transArchive_201407_201409_inactive_clean\"\n",
    "#my_table = \"transArchive_201410_201412_inactive_clean\"\n",
    "\n",
    "table_full_name = \".\".join([gbq_proj_id,gbq_dataset_id,my_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll test to see if that table exists and, if it doesn't, create it as an empty table. There's not natively a function to test for table existence in GBQ, so we'll write our own, which I found on StackOverflow [here](https://stackoverflow.com/questions/28731102/bigquery-check-if-table-already-exists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tbl_exists(client, table_ref):\n",
    "    from google.cloud.exceptions import NotFound\n",
    "    try:\n",
    "        client.get_table(table_ref)\n",
    "        return True\n",
    "    except NotFound:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tbl_exists(client, table_full_name) :\n",
    "    table_ref = client.create_table(\n",
    "        table = table_full_name\n",
    "    )\n",
    "else :\n",
    "    table_ref = client.get_table(table_full_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point our table is empty and doesn't even have a schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table transArchive_201410_201412_inactive_clean contains 0 columns\n"
     ]
    }
   ],
   "source": [
    "table = client.get_table(table_ref)\n",
    "print(\"Table {} contains {} columns\".format(table_ref.table_id,len(table.schema)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND\n",
    "job_config.schema_update_options = [\n",
    "    bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION # This allows us to modify the table. \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config.schema = [\n",
    "    bigquery.SchemaField(\"datetime\", \"TIMESTAMP\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"register_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"emp_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"upc\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"description\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_type\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_subtype\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_status\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"department\", \"NUMERIC\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"quantity\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Scale\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"cost\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"unitPrice\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"total\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"regPrice\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"altPrice\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"tax\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"taxexempt\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"foodstamp\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"wicable\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"discount\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"memDiscount\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"discountable\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"discounttype\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"voided\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"percentDiscount\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"ItemQtty\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"volDiscType\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"volume\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"VolSpecial\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"mixMatch\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"matched\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"memType\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"staff\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"numflag\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"itemstatus\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"tenderstatus\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"charflag\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"varflag\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"batchHeaderID\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"local\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"organic\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"display\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"receipt\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"card_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"store\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"branch\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"match_id\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_id\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "]\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.skip_leading_rows = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading tables to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads smaller files\n",
    "#with open(\"clean-files\\\\transArchive_201304_201306_inactive_clean.csv\", \"rb\") as source_file:\n",
    "#with open(\"clean-files\\\\transArchive_201301_201303_inactive_clean.csv\", \"rb\") as source_file:\n",
    "#with open(\"clean-files\\\\transArchive_201210_201212_inactive_clean.csv\", \"rb\") as source_file:\n",
    "#with open(\"clean-files\\\\transArchive_201207_201209_inactive_clean.csv\", \"rb\") as source_file:\n",
    "#with open(\"clean-files\\\\transArchive_201204_201206_inactive_clean.csv\", \"rb\") as source_file:\n",
    "#with open(\"clean-files\\\\transArchive_201201_201203_inactive_clean.csv\", \"rb\") as source_file:\n",
    "#with open(\"clean-files\\\\transArchive_201307_201309_inactive_clean.csv\", \"rb\") as source_file:\n",
    "#with open(\"clean-files\\\\transArchive_201310_201312_inactive_clean.csv\", \"rb\") as source_file:\n",
    "#with open(\"clean-files\\\\transArchive_201401_201403_inactive_clean.csv\", \"rb\") as source_file:\n",
    "#with open(\"clean-files\\\\transArchive_201404_201406_inactive_clean.csv\", \"rb\") as source_file:\n",
    "#with open(\"clean-files\\\\transArchive_201407_201409_inactive_clean.csv\", \"rb\") as source_file:\n",
    "#with open(\"clean-files\\\\transArchive_201410_201412_inactive_clean.csv\", \"rb\") as source_file:\n",
    "\n",
    "    \n",
    "    job = client.load_table_from_file(\n",
    "        source_file,\n",
    "        table_ref,\n",
    "        location=\"US\",  # Must match the destination dataset location.\n",
    "        job_config=job_config,\n",
    "    )  # API request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix file that wouldn't transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_fix = pd.read_csv(\"clean-files\\\\transArchive_201504_201506_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_fix\n",
    "#col_fix.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to change use .astype() \n",
    "col_fix['memType'] = col_fix.memType.astype(bool)\n",
    "col_fix['display'] = col_fix.display.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_fix\n",
    "#col_fix.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save as new CSV\n",
    "col_fix.to_csv(r'clean-files\\\\transArchive_201504_201506_clean.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
